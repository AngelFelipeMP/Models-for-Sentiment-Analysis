{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "igWqp0Hu7kSC"
   },
   "source": [
    "### 1) Importing Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nZf1KGPL7kSL"
   },
   "source": [
    "#### Standard Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "ZgrL-5zm7kSU",
    "outputId": "7ead50d1-8214-422c-c235-d879da75b123"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/angelfelipemagnossaodepaula/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ! source '/home/xicocaio/venv/bin/activate'\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from sklearn.datasets import load_files\n",
    "import pickle\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SPK62Xy7ezqL"
   },
   "source": [
    "#### Model Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Py0WduNw7kWH"
   },
   "outputs": [],
   "source": [
    "# Import Import RandomForestClassifier\n",
    "from sklearn.svm import SVR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kNgw5H7VbEVU"
   },
   "source": [
    "#### Downloading Files from Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1jnX5rhnYlca"
   },
   "outputs": [],
   "source": [
    "# Install the PyDrive wrapper & import libraries.\n",
    "# This only needs to be done once per notebook.\n",
    "# !pip install -U -q PyDrive\n",
    "# from pydrive.auth import GoogleAuth\n",
    "# from pydrive.drive import GoogleDrive\n",
    "# from google.colab import auth\n",
    "# from oauth2client.client import GoogleCredentials\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ei-2UGAqXsZ9"
   },
   "outputs": [],
   "source": [
    "# Authenticate and create the PyDrive client.\n",
    "# This only needs to be done once per notebook.\n",
    "# auth.authenticate_user()\n",
    "# gauth = GoogleAuth()\n",
    "# gauth.credentials = GoogleCredentials.get_application_default()\n",
    "# drive = GoogleDrive(gauth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CLyfQemgbnyH"
   },
   "outputs": [],
   "source": [
    "# Downloading Headlines train and Test Data from google drive\n",
    "# PS: the traing data is public and was downloaded to drive from:\n",
    "#        https://bitbucket.org/ssix-project/semeval-2017-task-5-subtask-2/raw/46143dc3c0c28b9286b6d1d424d1359c8f49d6cc/Headline_Trainingdata.json\n",
    "#     while the test data is avaliable n the same repo, but without labels\n",
    "#     the one used here was requested by e-mail, and contains labels\n",
    "\n",
    "# files_list = {'full_dict.txt': '1_ZBh3oFm3CYDqG3IcVY-ukG0-vsiulTp',\n",
    "#               'train.csv': '1Tjy8fxm63Yg9n7EemvJ_G_Fbs6Y6SQEC',\n",
    "#               'test.csv': '1NAQTM-0ynAQJ8CjHZ1AaxuMIuvuYjrgq',\n",
    "#               'SenVal_Functions.py': '1QgNS3191Q87tdXgyyJLrOqAlQf3wjki4'}\n",
    "\n",
    "# for filename, gdrive_id in files_list.items():\n",
    "#   exists = os.path.isfile('/content/' + filename)\n",
    "  \n",
    "#   if not exists:\n",
    "#     drive.CreateFile({'id': gdrive_id}).GetContentFile(filename)\n",
    "#     print('File {} was downloaded.'.format(filename))\n",
    "#   else:\n",
    "#     print('File {} not downloaded because already on system.'.format(filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C0SRWQjt7kS4"
   },
   "source": [
    "#### SenVal Evaluation Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "zl_sK9JE7kS8",
    "outputId": "2fd93104-41c1-4068-9294-b7dbafa9d5c8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/angelfelipemagnossaodepaula/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from SenVal_Functions import SenVal_metric\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "#New scoring function\n",
    "scoring_SenVal = make_scorer(SenVal_metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aEGghNeP7kTL"
   },
   "source": [
    "####  NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8l_LFX7H7kTQ"
   },
   "outputs": [],
   "source": [
    "from SenVal_Functions import NLP_pre_processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "R3fhQlPB7kTc"
   },
   "source": [
    "#### Dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NTpQF7tp7kTe"
   },
   "outputs": [],
   "source": [
    "#Dictionary with all the words in the corpus and only these\n",
    "with open(\"full_dict.txt\", \"rb\") as fp:   # Unpickling\n",
    "    full_dict = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "gmDvz1NF7kTq",
    "outputId": "f40c1cfb-f188-4097-f720-a5cc8ae1570c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     /Users/angelfelipemagnossaodepaula/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download dictionary WORDS from nltk\n",
    "import nltk\n",
    "nltk.download('words')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-UsYaG0f7kT5"
   },
   "source": [
    "### 2) Load files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YoAPTs1L7kT7"
   },
   "outputs": [],
   "source": [
    "#test\n",
    "df_test = pd.read_csv('test.csv', index_col='id')\n",
    "#train\n",
    "df_train = pd.read_csv('train.csv', index_col='id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tiVWygYx7kUE"
   },
   "source": [
    "### 3) Split dataset in \" Title \" and \" Label \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SpxeEA6H7kUG"
   },
   "outputs": [],
   "source": [
    "#Train_Title\n",
    "train_title = []\n",
    "for n in df_train['title']:\n",
    "    train_title.append(n)\n",
    "    \n",
    "#Train_Label\n",
    "train_label = df_train['sentiment_range'].values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R-HdWwh77kUT"
   },
   "outputs": [],
   "source": [
    "#Test_Title\n",
    "test_title = []\n",
    "for n in df_test['title']:\n",
    "    test_title.append(n)\n",
    "      \n",
    "#Test_Label\n",
    "test_label = df_test['sentiment_range'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ice-56oL7kUk"
   },
   "source": [
    "### 4) Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "naz2XtV-7kUl"
   },
   "outputs": [],
   "source": [
    "# Applying the NLP_pre_processing function \n",
    "\n",
    "#Train\n",
    "documents_train = NLP_pre_processing(train_title)\n",
    "#Test\n",
    "documents_test = NLP_pre_processing(test_title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XRDZ5kmo7kUt"
   },
   "source": [
    "### 5) Converting Text to Numbers "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "brjphp-67kUw"
   },
   "source": [
    "#### Dictionary Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZHUtQz0n7kUz"
   },
   "outputs": [],
   "source": [
    "# Import dictionary WORDS from nltk\n",
    "from nltk.corpus import words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YpMWgF227kU7"
   },
   "outputs": [],
   "source": [
    "# Convert dictionary to set and add it into\" vocab \"\n",
    "vocab = set(words.words())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xQ8HOJtS7kVD"
   },
   "source": [
    "#### Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cJTwKRpG7kVF"
   },
   "outputs": [],
   "source": [
    "# Import CountVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lZgocyyR7kVL"
   },
   "outputs": [],
   "source": [
    "#Train\n",
    "vectorizer_train = CountVectorizer(max_features=1500, vocabulary= full_dict, min_df=5, max_df=0.7, stop_words=stopwords.words('english'))  \n",
    "train_title = vectorizer_train.fit_transform(documents_train).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5Sot0AKR7kVU"
   },
   "outputs": [],
   "source": [
    "#Test\n",
    "vectorizer_test = CountVectorizer(max_features=1500, vocabulary= full_dict, min_df=5, max_df=0.7, stop_words=stopwords.words('english'))  \n",
    "test_title = vectorizer_test.fit_transform(documents_test).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9qGdoGj07kVc"
   },
   "source": [
    "#### Finding TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Os7b1tIl7kVf"
   },
   "outputs": [],
   "source": [
    "# Import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fOTq3dcG7kVj"
   },
   "outputs": [],
   "source": [
    "#Train\n",
    "tfidfconverter_train = TfidfTransformer()\n",
    "train_title = tfidfconverter_train.fit_transform(train_title).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KblrVRqv7kVp"
   },
   "outputs": [],
   "source": [
    "#Test\n",
    "tfidfconverter_test = TfidfTransformer()\n",
    "test_title = tfidfconverter_test.fit_transform(test_title).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-JrWHcbM7kVt"
   },
   "source": [
    "### 6) Training and Testing Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rINQuLGD7kVv"
   },
   "outputs": [],
   "source": [
    "# Import train_test_split\n",
    "from sklearn.model_selection import train_test_split  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-yLvVYyH7kV2"
   },
   "outputs": [],
   "source": [
    "#Train and Validation\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(train_title, train_label, test_size=0.20, random_state=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qFzlI16q7kV-"
   },
   "outputs": [],
   "source": [
    "#Test\n",
    "#X_test, X, y_test, y = train_test_split(test_title, test_label, test_size=0, shuffle=False)\n",
    "X_test = test_title\n",
    "y_test = test_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(913, 4235)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(913,)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3xOxR90d7kWF"
   },
   "source": [
    "### 7) Grid Search for Parameter Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NP5-bL0c7kWG"
   },
   "source": [
    "#### SVM algorithm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s6u0p0o_7kWM"
   },
   "outputs": [],
   "source": [
    "# Set the classifier_1\n",
    "classifier_1 = SVR() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wjTvBN_07kWQ"
   },
   "source": [
    "#### Specify Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j5WHbBiz7kWT"
   },
   "outputs": [],
   "source": [
    "# Import the Grid Search algorithm \n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qEckUDgZ7kWb"
   },
   "outputs": [],
   "source": [
    "#Grid Search parameters\n",
    "# C_range = np.logspace(-2, 5, 13)\n",
    "# gamma_range = np.logspace(-9, 3, 13)\n",
    "# degree_range = np.arange(2,8,1)\n",
    "\n",
    "C_range = np.logspace(-2, 5, 13)\n",
    "gamma_range = np.logspace(-9, 1, 2)\n",
    "degree_range = np.arange(2,3,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gZrKsOHE7kWh"
   },
   "outputs": [],
   "source": [
    "# Create a dictionary of parameters and their corresponding values for Random Forest algorithm\n",
    "grid_param = {\n",
    "   'kernel':['poly'],\n",
    "   'degree':degree_range,\n",
    "   'gamma':gamma_range ,\n",
    "   'C':C_range\n",
    "}\n",
    "\n",
    "# #Create a dictionary of parameters and their corresponding values for Random Forest algorithm\n",
    "# grid_param = {\n",
    "#     'kernel': ['linear', 'rbf', 'sigmoid'],\n",
    "#     'C': C_range,\n",
    "#     'gamma': gamma_range,\n",
    "#     'degree': degree_range\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Q8V9pezy7kWk"
   },
   "outputs": [],
   "source": [
    "#Create an instance of the GridSearchCV class \n",
    "\n",
    "# Apply in the real train !!!\n",
    "# gd_sr = GridSearchCV(estimator=classifier_1,  \n",
    "#                     param_grid=grid_param,\n",
    "#                     scoring= neg_mean_squared_error',\n",
    "#                     cv=10,\n",
    "#                     n_jobs=-1)\n",
    "\n",
    "gd_sr = GridSearchCV(estimator=classifier_1,  \n",
    "                     param_grid=grid_param,\n",
    "                     scoring='neg_mean_squared_error',\n",
    "                     cv=2,\n",
    "                     n_jobs=-1,\n",
    "                     verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 717
    },
    "colab_type": "code",
    "id": "6FCaKqqE7kWp",
    "outputId": "18f36444-eb77-41e2-937f-ec99b6697ffb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 26 candidates, totalling 52 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   33.9s\n",
      "[Parallel(n_jobs=-1)]: Done  52 out of  52 | elapsed:   40.1s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=2, error_score='raise-deprecating',\n",
       "       estimator=SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1,\n",
       "  gamma='auto_deprecated', kernel='rbf', max_iter=-1, shrinking=True,\n",
       "  tol=0.001, verbose=False),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid={'kernel': ['poly'], 'degree': array([2]), 'gamma': array([1.e-09, 1.e+01]), 'C': array([1.00000e-02, 3.83119e-02, 1.46780e-01, 5.62341e-01, 2.15443e+00,\n",
       "       8.25404e+00, 3.16228e+01, 1.21153e+02, 4.64159e+02, 1.77828e+03,\n",
       "       6.81292e+03, 2.61016e+04, 1.00000e+05])},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='neg_mean_squared_error', verbose=1)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fit method of the class and pass it the training and test set\n",
    "gd_sr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Y-YPXV8C7kWx"
   },
   "source": [
    "#### Check the parameters that return the lowest Mean squared errer MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "tXrQjOjv7kWx",
    "outputId": "e620bc1f-e738-4a72-ee66-4cb6159aeda8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.01, 'degree': 2, 'gamma': 10.0, 'kernel': 'poly'}\n"
     ]
    }
   ],
   "source": [
    "best_parameters = gd_sr.best_params_\n",
    "print(best_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7XS2DlIW7kW7"
   },
   "source": [
    "#### Find the Mean squared errer (MSE) obtained using the best parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aSYxXFi1dq31"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "C8ZmTDy_7kW8",
    "outputId": "bf0a0fa7-66c6-49a0-a30b-ff6f4fd377fc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1267464155758865\n"
     ]
    }
   ],
   "source": [
    "best_result = -gd_sr.best_score_\n",
    "print(best_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1nqWxrdDhAbr"
   },
   "source": [
    "#### Specify Grid Search 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n2CaR8wLg5MZ"
   },
   "outputs": [],
   "source": [
    "#Grid Search parameters\n",
    "C_range = np.logspace(-2, 5, 13)\n",
    "gamma_range = np.logspace(-9, 1, 13)\n",
    "degree_range = np.arange(2,8,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s88StYO580Ib"
   },
   "outputs": [],
   "source": [
    "#Create a dictionary of parameters and their corresponding values for Random Forest algorithm\n",
    "grid_param = {\n",
    "    'kernel': ['linear', 'rbf', 'sigmoid'],\n",
    "    'C': C_range,\n",
    "    'gamma': gamma_range,\n",
    "    'degree': degree_range\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qXX8_mH77kXD"
   },
   "source": [
    "### 9) Predicting Sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WvhvemsD7kXF"
   },
   "source": [
    "#### Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s5QoWd8P7kXG"
   },
   "outputs": [],
   "source": [
    "#Train\n",
    "vectorizer_train = CountVectorizer(max_features=1500, vocabulary= vocab, min_df=5, max_df=0.7, stop_words=stopwords.words('english'))  \n",
    "train_title = vectorizer_train.fit_transform(documents_train).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M2qOhZp27kXK"
   },
   "outputs": [],
   "source": [
    "#Test\n",
    "vectorizer_test = CountVectorizer(max_features=1500, vocabulary= vocab, min_df=5, max_df=0.7, stop_words=stopwords.words('english'))  \n",
    "test_title = vectorizer_test.fit_transform(documents_test).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PdI_Dd1h7kXN"
   },
   "source": [
    "#### Finding TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TM0GlCzV7kXR"
   },
   "outputs": [],
   "source": [
    "#Train\n",
    "tfidfconverter_train = TfidfTransformer()\n",
    "train_title = tfidfconverter_train.fit_transform(train_title).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "spwEmtU77kXU"
   },
   "outputs": [],
   "source": [
    "#Test\n",
    "tfidfconverter_test = TfidfTransformer()\n",
    "test_title = tfidfconverter_test.fit_transform(test_title).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lE2DHede7kXZ"
   },
   "source": [
    "#### Training Using the full \" train dataset \" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Q5aYMHdB7kXc"
   },
   "outputs": [],
   "source": [
    "#Test\n",
    "X_train_full = train_title\n",
    "y_train_full = train_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "7XZWysMx7kXi",
    "outputId": "674f7268-8e51-4402-887f-1aff06047f1f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVR(C=1, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma=10,\n",
       "  kernel='poly', max_iter=-1, shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 55,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set the classifier_2\n",
    "classifier_2 = SVR(kernel='poly', degree= 3, gamma= 10, C= 1)\n",
    "classifier_2.fit(X_train_full, y_train_full)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "h4Exf16g7kXp"
   },
   "source": [
    "#### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 401
    },
    "colab_type": "code",
    "id": "sPIUKz527kXq",
    "outputId": "a0e465cf-e8ca-48af-bedf-85891ba4f273"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-b9f2b27f2c9f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifier_2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/venv/lib/python3.5/site-packages/sklearn/svm/base.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m         \"\"\"\n\u001b[0;32m--> 325\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_for_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m         \u001b[0mpredict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sparse_predict\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sparse\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dense_predict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.5/site-packages/sklearn/svm/base.py\u001b[0m in \u001b[0;36m_validate_for_predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    476\u001b[0m             raise ValueError(\"X.shape[1] = %d should be equal to %d, \"\n\u001b[1;32m    477\u001b[0m                              \u001b[0;34m\"the number of features at training time\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 478\u001b[0;31m                              (n_features, self.shape_fit_[1]))\n\u001b[0m\u001b[1;32m    479\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: X.shape[1] = 4235 should be equal to 235892, the number of features at training time"
     ]
    }
   ],
   "source": [
    "y_pred = classifier_2.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wueWLcW37kXu"
   },
   "source": [
    "### 10) Evaluating the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-f4LWLpz7kXw"
   },
   "source": [
    "#### Ordinary metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pIaIXZxv7kXx",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Import Import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_test,y_pred))  \n",
    "print('Mean Squred Error:', mean_squared_error(y_test,y_pred))  \n",
    "print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_test, y_pred)))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UOMY4eEd7kX6"
   },
   "source": [
    "#### SanVal metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jSP6PyXW7kX7"
   },
   "outputs": [],
   "source": [
    "#Reshape matrix\n",
    "#Predict\n",
    "y_pred=y_pred.reshape(1,-1)\n",
    "#Label\n",
    "y_test=y_test.reshape(1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sCZL6OUU7kYA"
   },
   "outputs": [],
   "source": [
    "SenVal_metric(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-s73vrOF7kYJ"
   },
   "source": [
    "### Graphics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cL-_oh_Z7kYL"
   },
   "source": [
    "### Validatio Curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fJWMlUCE7kYM"
   },
   "source": [
    "#### GAMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W_nkOQ0c7kYN"
   },
   "outputs": [],
   "source": [
    "#Import Validation Curve\n",
    "from SenVal_Functions import plot_validation_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qaT_Ymet7kYS"
   },
   "outputs": [],
   "source": [
    "#Set parameters range\n",
    "#estimator = SVR()\n",
    "estimator = classifier_2\n",
    "title = \"Validation Curve with SVR\"\n",
    "x_label = r\"$\\gamma$\"\n",
    "param_name='gamma'\n",
    "ylim = (0,1)\n",
    "gamma_range = np.logspace(-9, 3, 13)\n",
    "cv=2\n",
    "n_jobs=-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EArZTKys7kYZ"
   },
   "outputs": [],
   "source": [
    "#Apply Validation Curve\n",
    "plot_validation_curve(estimator, title, x_label, X_train_full, y_train_full, param_name, gamma_range, ylim, cv, n_jobs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oRMKX_-_7kYg"
   },
   "source": [
    "#### C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EENjQCxb7kYj"
   },
   "outputs": [],
   "source": [
    "#Set parameters range\n",
    "#estimator = SVR()\n",
    "estimator = classifier_2\n",
    "title = \"Validation Curve with SVR\"\n",
    "x_label = r\"C\"\n",
    "param_name='C'\n",
    "ylim = (0,1)\n",
    "C_range = np.logspace(-2, 5, 13)\n",
    "cv=2\n",
    "n_jobs=-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "smJ8fIVS7kYo"
   },
   "outputs": [],
   "source": [
    "#Apply Validation Curve\n",
    "plot_validation_curve(estimator, title, x_label, X_train_full, y_train_full, param_name, C_range, ylim, cv, n_jobs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FWE8Cdw97kYx"
   },
   "source": [
    "#### Degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xQt1reHe7kYy"
   },
   "outputs": [],
   "source": [
    "#Set parameters range\n",
    "#estimator = SVR()\n",
    "estimator = classifier_2\n",
    "title = \"Validation Curve with SVR\"\n",
    "x_label = r\"degree\"\n",
    "param_name='degree'\n",
    "ylim = (0.1,0.5)\n",
    "degree_range = np.arange(2,8,1)\n",
    "cv=2\n",
    "n_jobs=-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZPlU7qFl7kY2"
   },
   "outputs": [],
   "source": [
    "#Apply Validation Curve\n",
    "plot_validation_curve(estimator, title, x_label, X_train_full, y_train_full, param_name, degree_range, ylim, cv, n_jobs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lK8a_sIA7kZA"
   },
   "source": [
    "### Learning Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cLvOk0wA7kZB"
   },
   "outputs": [],
   "source": [
    "# Import curve/plot\n",
    "from SenVal_Functions import plot_learning_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s6dBNEsn7kZF"
   },
   "outputs": [],
   "source": [
    "# Set the of learn curve plot\n",
    "estimator = SVR(kernel='linear')\n",
    "title = r\"Learning Curves (SVR, Linear kernel, $\\gamma=0.001$)\"\n",
    "ylim=(0,0.2)\n",
    "cv=2\n",
    "n_jobs=-1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "q188jmdi7kZI"
   },
   "outputs": [],
   "source": [
    "#Apply learning Curve\n",
    "plot_learning_curve(estimator, title, X_train_full, y_train_full, ylim, cv, n_jobs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "K-xYW3lf7kZQ"
   },
   "source": [
    "### 13) Saving and Loading the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TkoNb28C7kZR"
   },
   "outputs": [],
   "source": [
    "with open('SVM_Regrassion_2', 'wb') as picklefile:\n",
    "    pickle.dump(classifier_2,picklefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Mv0HAeI87kZV"
   },
   "outputs": [],
   "source": [
    "    #Load Model\n",
    "#with open('text_classifier', 'rb') as training_model:  \n",
    "    #model = pickle.load(training_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4r7RYZwed-P3"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "(Regression) SVR.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
